# HackHarvard17_project

# Inspiration
One member of our team brought us a touching story about how a member of his family with a visual disability struggles to use internet and computers. Something that is so common in our lives but that we don't appreciate. Our goal for this Hackathon was to put ourselves in a blind person shoes and try to use the computer. That lead us to create a voice based extension that later we improved adding AI to learn from our browsing behavior and to expand also the possibilities of our experience.

# What it does
When the extension is activated. It waits till it receives a voice command. Execute it. The AI learn it and retrain a model based on our browsing behavior. Wash, Rinse and Repeat



# INSTRUCTION!
To run locally     
1. Install nodejs and npm. Then install gulp package globally    
2. Locate project folder in terminal      
3. Type "npm install" to install node packages   
4. Type "npm run nodeapp" to start the server and app

then you will have to install Chrome Extension locally.
To do that, follow the instruction bellow:
1. Navigate to chrome://extensions
2. Expand the Developer dropdown menu and click “Load Unpacked Extension”
3. Navigate to the local folder containing the extension’s code and click Ok
4. Assuming there are no errors, the extension should load into your browser 

after that navigate to facebook.com and click on a new ico "A.I." in the top right app drawer and then allows to use
your micro to recognize your commands. 
Now, by scrolling you feed wall you can say "i don't like it" and the A.I. will learn it + hide it from you page and then extension in connection with A.I. will improve your browsering experience by removing unpleasant stuff. 




